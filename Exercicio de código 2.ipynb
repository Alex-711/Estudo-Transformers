{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52686089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c66f6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "  \"\"\" Scaled dot product attention. \"\"\"\n",
    "\n",
    "  def __init__(self, dropout, **kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a Scaled Dot Product Attention Instance.\n",
    "\n",
    "    Args:\n",
    "      dropout: Integer\n",
    "        Specifies probability of dropout hyperparameter\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    super(DotProductAttention, self).__init__(**kwargs)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def calculate_score(self, queries, keys):\n",
    "      \"\"\"\n",
    "      Compute the score between queries and keys.\n",
    "\n",
    "      Args:\n",
    "      queries: Tensor\n",
    "        Query is your search tag/Question\n",
    "        Shape of `queries`: (`batch_size`, no. of queries, head,`k`)\n",
    "      keys: Tensor\n",
    "        Descriptions associated with the database for instance\n",
    "        Shape of `keys`: (`batch_size`, no. of key-value pairs, head, `k`)\n",
    "      \"\"\"\n",
    "      return torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(queries.shape[-1])\n",
    "\n",
    "  def forward(self, queries, keys, values, b, h, t, k):\n",
    "    \"\"\"\n",
    "    Compute dot products. This is the same operation for each head,\n",
    "    so we can fold the heads into the batch dimension and use torch.bmm\n",
    "    Note: .contiguous() doesn't change the actual shape of the data,\n",
    "    but it rearranges the tensor in memory, which will help speed up the computation\n",
    "    for this batch matrix multiplication.\n",
    "    .transpose() is used to change the shape of a tensor. It returns a new tensor\n",
    "    that shares the data with the original tensor. It can only swap two dimensions.\n",
    "\n",
    "    Args:\n",
    "      queries: Tensor\n",
    "        Query is your search tag/Question\n",
    "        Shape of `queries`: (`batch_size`, no. of queries, head,`k`)\n",
    "      keys: Tensor\n",
    "        Descriptions associated with the database for instance\n",
    "        Shape of `keys`: (`batch_size`, no. of key-value pairs, head, `k`)\n",
    "      values: Tensor\n",
    "        Values are returned results on the query\n",
    "        Shape of `values`: (`batch_size`, head, no. of key-value pairs,  `k`)\n",
    "      b: Integer\n",
    "        Batch size\n",
    "      h: Integer\n",
    "        Number of heads\n",
    "      t: Integer\n",
    "        Number of keys/queries/values (for simplicity, let's assume they have the same sizes)\n",
    "      k: Integer\n",
    "        Embedding size\n",
    "\n",
    "    Returns:\n",
    "      out: Tensor\n",
    "        Matrix Multiplication between the keys, queries and values.\n",
    "    \"\"\"\n",
    "    keys = keys.transpose(1, 2).contiguous().view(b * h, t, k)\n",
    "    queries = queries.transpose(1, 2).contiguous().view(b * h, t, k)\n",
    "    values = values.transpose(1, 2).contiguous().view(b * h, t, k)\n",
    "\n",
    "    #################################################\n",
    "    ## Implement Scaled dot product attention\n",
    "    # See the shape of the queries and keys above. You may want to use the `transpose` function\n",
    "    raise NotImplementedError(\"Scaled dot product attention `forward`\")\n",
    "    #################################################\n",
    "\n",
    "    # Matrix Multiplication between the keys and queries\n",
    "    score = self.calculate_score(queries, keys)  # size: (b * h, t, t)\n",
    "    softmax_weights = F.softmax(score, dim=2)  # row-wise normalization of weights\n",
    "\n",
    "    # Matrix Multiplication between the output of the key and queries multiplication and values.\n",
    "    out = torch.bmm(self.dropout(...), values).view(b, h, t, k)  # rearrange h and t dims\n",
    "    out = out.transpose(1, 2).contiguous().view(b, t, h * k)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f7f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "braindecode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
